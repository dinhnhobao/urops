1. Effective of SeLUs:
https://shaoanlu.wordpress.com/2017/06/14/toy-experiment-on-selus-scaled-exponential-linear-units/
https://towardsdatascience.com/selu-make-fnns-great-again-snn-8d61526802a9
2. Comparison of activation functions:
https://github.com/shaohua0116/Activation-Visualization-Histogram
3. h5py my own experience verification:
https://shocksolution.com/2010/01/10/storing-large-numpy-arrays-on-disk-python-pickle-vs-hdf5adsf/
4. The see "these links":
https://github.com/aymericdamien/TensorFlow-Examples
https://www.tensorflow.org/versions/r1.0/get_started/mnist/pros
5. Mean subtraction and normalization:
http://cs231n.github.io/neural-networks-2/ 
